import random
import torch
import gradio as gr
from PIL import Image
from diffsynth import save_video, VideoData
from diffsynth.pipelines.wan_video_new import WanVideoPipeline, ModelConfig
import time
import os
import gc

from video_utils import clean_temp_videos, reencode_video_to_16fps, get_video_info
from img_utils import get_image_info
from vram_utils import clear_vram, get_vram_info

ASPECT_RATIOS_14b = {
    "1:1":  (960, 960),
    "4:3":  (1104, 832),
    "3:4":  (832, 1104),
    "3:2":  (1152, 768),
    "2:3":  (768, 1152),
    "16:9": (1280, 720),
    "16:9_low": (832, 480),
    "9:16": (720, 1280),
    "9:16_low": (480, 832),
    "21:9": (1472, 624),
    "9:21": (624, 1472),
    "4:5":  (864, 1072),
    "5:4":  (1072, 864),
}

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# å…¨å±€å˜é‡å­˜å‚¨pipelineå’Œæ¨¡å‹é€‰æ‹©
pipe:WanVideoPipeline = None
selected_model = "PAI/Wan2.2-VACE-Fun-A14B"  # é»˜è®¤é€‰æ‹©14Bæ¨¡å‹
input_mode = "vace"  # é»˜è®¤è¾“å…¥æ¨¡å¼ï¼švaceï¼ˆæ·±åº¦è§†é¢‘+å‚è€ƒå›¾ç‰‡ï¼‰æˆ– inpï¼ˆé¦–å°¾å¸§ï¼‰

# å®šä¹‰ä¸åŒæ¨¡å¼å¯¹åº”çš„æ¨¡å‹åˆ—è¡¨
VACE_MODELS = [
    "PAI/Wan2.2-VACE-Fun-A14B",
    "Wan-AI/Wan2.1-VACE-1.3B"
]

INP_MODELS = [
    "PAI/Wan2.2-Fun-A14B-InP",
    "PAI/Wan2.1-Fun-V1.1-1.3B-InP"
]

def get_models_by_mode(mode):
    """æ ¹æ®è¾“å…¥æ¨¡å¼è¿”å›å¯¹åº”çš„æ¨¡å‹åˆ—è¡¨"""
    if mode == "vace":
        return VACE_MODELS
    elif mode == "inp":
        return INP_MODELS
    else:
        return VACE_MODELS  # é»˜è®¤è¿”å›VACEæ¨¡å‹

def handle_tab_change(evt: gr.SelectData):
    """å¤„ç†Tabåˆ‡æ¢äº‹ä»¶"""
    # evt.index: 0 = VACEæ¨¡å¼, 1 = é¦–å°¾å¸§æ¨¡å¼
    if evt.index == 0:  # VACEæ¨¡å¼
        models = VACE_MODELS
        default_model = VACE_MODELS[0]
        mode = "vace"
    else:  # é¦–å°¾å¸§æ¨¡å¼
        models = INP_MODELS
        default_model = INP_MODELS[0]
        mode = "inp"
    
    # æ›´æ–°å…¨å±€å˜é‡
    global input_mode, selected_model
    input_mode = mode
    selected_model = default_model
    
    # è¿”å›æ–°çš„æ¨¡å‹é€‰æ‹©åˆ—è¡¨å’Œé»˜è®¤å€¼
    return gr.Dropdown(choices=models, value=default_model)


def update_dimensions(aspect_ratio):
    """æ ¹æ®é€‰æ‹©çš„å®½é«˜æ¯”æ›´æ–°é«˜åº¦å’Œå®½åº¦"""
    if aspect_ratio in ASPECT_RATIOS_14b:
        width, height = ASPECT_RATIOS_14b[aspect_ratio]
        return height, width
    return 480, 832  # é»˜è®¤å€¼


def initialize_pipeline(model_id="PAI/Wan2.2-VACE-Fun-A14B", vram_limit=6.0):
    """åˆå§‹åŒ–WanVideoPipeline"""
    global pipe, selected_model, input_mode
    
    # å¦‚æœæ¨¡å‹æ”¹å˜äº†ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
    if pipe is not None and selected_model != model_id:
        print(f"æ¨¡å‹ä» {selected_model} åˆ‡æ¢åˆ° {model_id}ï¼Œé‡æ–°åˆå§‹åŒ–...")
        del pipe
        pipe = None
        torch.cuda.empty_cache()
        gc.collect()
    
    if pipe is None:
        print(f"æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: {model_id}")
        selected_model = model_id
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®è¾“å…¥æ¨¡å¼
        if "InP" in model_id:
            input_mode = "inp"
        else:
            input_mode = "vace"
        
        if model_id == "PAI/Wan2.2-VACE-Fun-A14B":
            # 14B VACEæ¨¡å‹é…ç½®
            pipe = WanVideoPipeline.from_pretrained(
                torch_dtype=torch.bfloat16,
                device="cuda",
                model_configs=[
                    ModelConfig(model_id="PAI/Wan2.2-VACE-Fun-A14B", origin_file_pattern="high_noise_model/diffusion_pytorch_model*.safetensors", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.2-VACE-Fun-A14B", origin_file_pattern="low_noise_model/diffusion_pytorch_model*.safetensors", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.2-VACE-Fun-A14B", origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.2-VACE-Fun-A14B", origin_file_pattern="Wan2.1_VAE.pth", offload_device="cpu"),
                ],
            )
        elif model_id == "Wan-AI/Wan2.1-VACE-1.3B":
            # 1.3B VACEæ¨¡å‹é…ç½®
            pipe = WanVideoPipeline.from_pretrained(
                torch_dtype=torch.bfloat16,
                device="cuda",
                model_configs=[
                    ModelConfig(model_id="Wan-AI/Wan2.1-VACE-1.3B", origin_file_pattern="diffusion_pytorch_model*.safetensors", offload_device="cpu"),
                    ModelConfig(model_id="Wan-AI/Wan2.1-VACE-1.3B", origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth", offload_device="cpu"),
                    ModelConfig(model_id="Wan-AI/Wan2.1-VACE-1.3B", origin_file_pattern="Wan2.1_VAE.pth", offload_device="cpu"),
                ],
            )
        elif model_id == "PAI/Wan2.2-Fun-A14B-InP":
            # 14B InPæ¨¡å‹é…ç½®
            pipe = WanVideoPipeline.from_pretrained(
                torch_dtype=torch.bfloat16,
                device="cuda",
                model_configs=[
                    ModelConfig(model_id="PAI/Wan2.2-Fun-A14B-InP", origin_file_pattern="high_noise_model/diffusion_pytorch_model*.safetensors", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.2-Fun-A14B-InP", origin_file_pattern="low_noise_model/diffusion_pytorch_model*.safetensors", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.2-Fun-A14B-InP", origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.2-Fun-A14B-InP", origin_file_pattern="Wan2.1_VAE.pth", offload_device="cpu"),
                ],
            )
        elif model_id == "PAI/Wan2.1-Fun-V1.1-1.3B-InP":
            # 1.3B InPæ¨¡å‹é…ç½®
            pipe = WanVideoPipeline.from_pretrained(
                torch_dtype=torch.bfloat16,
                device="cuda",
                model_configs=[
                    ModelConfig(model_id="PAI/Wan2.1-Fun-V1.1-1.3B-InP", origin_file_pattern="diffusion_pytorch_model*.safetensors", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.1-Fun-V1.1-1.3B-InP", origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.1-Fun-V1.1-1.3B-InP", origin_file_pattern="Wan2.1_VAE.pth", offload_device="cpu"),
                    ModelConfig(model_id="PAI/Wan2.1-Fun-1.3B-InP", origin_file_pattern="models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth", offload_device="cpu"),
                ],
            )
        
        # å°†GBè½¬æ¢ä¸ºå­—èŠ‚
        num_persistent_param_in_dit = int(vram_limit * 1024**3)
        pipe.enable_vram_management(num_persistent_param_in_dit=num_persistent_param_in_dit)
        
        print(f"Pipelineåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model_id}")
        print(f"è¾“å…¥æ¨¡å¼: {input_mode}")
        print(f"æ˜¾å­˜é™åˆ¶: {vram_limit}GB")
    return f"Pipelineåˆå§‹åŒ–å®Œæˆï¼ä½¿ç”¨æ¨¡å‹: {model_id} (æ¨¡å¼: {input_mode})"


def process_video(
    depth_video,
    reference_image,
    prompt,
    negative_prompt,
    seed,
    fps,
    quality,
    height,
    width,
    num_frames,
    num_inference_steps,
    vram_limit,
    model_id,
    first_frame=None,
    last_frame=None,
    tiled=True
):
    """å¤„ç†è§†é¢‘ç”Ÿæˆ"""
    try:
        # æ ¹æ®æ¨¡å‹ç±»å‹åˆ¤æ–­è¾“å…¥æ¨¡å¼
        is_inp_mode = "InP" in model_id
        
        if is_inp_mode:
            # InPæ¨¡å¼ï¼šéœ€è¦é¦–å¸§ï¼Œå°¾å¸§å¯é€‰
            has_first_frame = first_frame is not None
            if not has_first_frame:
                return None, "é”™è¯¯ï¼šé¦–å°¾å¸§æ¨¡å¼éœ€è¦ä¸Šä¼ é¦–å¸§å›¾ç‰‡"
        else:
            # VACEæ¨¡å¼ï¼šéœ€è¦æ·±åº¦è§†é¢‘æˆ–å‚è€ƒå›¾ç‰‡
            has_depth_video = depth_video is not None and depth_video != ""
            has_reference_image = reference_image is not None
            if not has_depth_video and not has_reference_image:
                return None, "é”™è¯¯ï¼šè¯·è‡³å°‘ä¸Šä¼ æ·±åº¦è§†é¢‘æˆ–å‚è€ƒå›¾ç‰‡ä¸­çš„ä¸€ç§"
        
        if seed < 0:
            seed = random.randint(1, 2**32 - 1)
        
        # è‡ªåŠ¨åˆå§‹åŒ–pipelineï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
        if pipe is None:
            status = initialize_pipeline(model_id, vram_limit)
            if "å®Œæˆ" not in status:
                return None, f"model_idåˆå§‹åŒ–å¤±è´¥ï¼š{status}"
        
        vace_video = None
        vace_reference_image = None

        if not prompt:
            prompt = "ä¸¤åªå¯çˆ±çš„æ©˜çŒ«æˆ´ä¸Šæ‹³å‡»æ‰‹å¥—ï¼Œç«™åœ¨ä¸€ä¸ªæ‹³å‡»å°ä¸Šææ–—ã€‚"
        
        if not negative_prompt:
            negative_prompt = "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°"
        
        if is_inp_mode:
            # InPæ¨¡å¼ï¼šå¤„ç†é¦–å°¾å¸§
            if has_first_frame:
                print(f"è°ƒè¯•ä¿¡æ¯ï¼šé¦–å¸§å›¾ç‰‡ = {first_frame}, ç±»å‹ = {type(first_frame)}")
                if isinstance(first_frame, str):
                    first_frame_img = Image.open(first_frame).resize((width, height)).convert("RGB")
                else:
                    first_frame_img = first_frame.resize((width, height)).convert("RGB")
                
                # å¦‚æœæœ‰å°¾å¸§ï¼Œä¹Ÿå¤„ç†
                last_frame_img = None
                if last_frame is not None:
                    print(f"è°ƒè¯•ä¿¡æ¯ï¼šå°¾å¸§å›¾ç‰‡ = {last_frame}, ç±»å‹ = {type(last_frame)}")
                    if isinstance(last_frame, str):
                        last_frame_img = Image.open(last_frame).resize((width, height)).convert("RGB")
                    else:
                        last_frame_img = last_frame.resize((width, height)).convert("RGB")
                
                # è°ƒç”¨InPæ¨¡å‹çš„pipeline
                video = pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    input_image=first_frame_img,
                    end_image=last_frame_img,
                    seed=seed,
                    tiled=True,
                    height=height,
                    width=width,
                    num_frames=num_frames,
                    num_inference_steps=num_inference_steps,
                    cfg_scale=6.0,
                    sigma_shift=6.0,
                )
            else:
                return None, "é¦–å°¾å¸§æ¨¡å¼éœ€è¦ä¸Šä¼ é¦–å¸§å›¾ç‰‡"
        else:
            # VACEæ¨¡å¼ï¼šå¤„ç†æ·±åº¦è§†é¢‘å’Œå‚è€ƒå›¾ç‰‡
            if has_depth_video:
                # Gradio Videoç»„ä»¶è¿”å›çš„æ˜¯æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
                temp_video_path = depth_video
                print(f"è°ƒè¯•ä¿¡æ¯ï¼šæ·±åº¦è§†é¢‘è·¯å¾„ = {temp_video_path}, ç±»å‹ = {type(temp_video_path)}")
                print(f"ç›®æ ‡å°ºå¯¸: {width}x{height}")
                # æŠŠç›®æ ‡è§†é¢‘å®½é«˜å’Œå¸§ç‡è½¬æ¢ä¸º16fps
                temp_video_path = reencode_video_to_16fps(temp_video_path, num_frames, width, height)
                
                # åˆ›å»ºVideoDataæ—¶æŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨è°ƒæ•´
                try:
                    vace_video = VideoData(temp_video_path, height=height, width=width)
                    print(f"æˆåŠŸåˆ›å»ºVideoDataï¼Œå°ºå¯¸: {width}x{height}")
                except Exception as e:
                    print(f"VideoDataåˆ›å»ºå¤±è´¥: {e}")
                    return None, f"æ·±åº¦è§†é¢‘å¤„ç†å¤±è´¥ï¼š{str(e)}\nè¯·ç¡®ä¿è§†é¢‘å°ºå¯¸ä¸ç›®æ ‡å°ºå¯¸å…¼å®¹"
            
            if has_reference_image:
                print(f"è°ƒè¯•ä¿¡æ¯ï¼šå‚è€ƒå›¾ç‰‡ = {reference_image}, ç±»å‹ = {type(reference_image)}")
                if isinstance(reference_image, str):
                    vace_reference_image = Image.open(reference_image).resize((width, height)).convert("RGB")
                else:
                    vace_reference_image = reference_image.resize((width, height)).convert("RGB")
        
            video = pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                vace_video=vace_video,
                vace_reference_image=vace_reference_image,
                seed=seed,
                tiled=tiled,
                height=height,
                width=width,
                num_frames=num_frames,
                num_inference_steps=num_inference_steps,
                cfg_scale=6.0,
                sigma_shift=6.0,
                vace_scale=0.8,
            )
        
        timestamp = int(time.time())
        output_path = f"output_video_{seed}_{timestamp}.mp4"
        save_video(video, output_path, fps=fps, quality=quality)

        print("cleaning temp videos...")
        clean_temp_videos()
        print("clearing vram...")
        clear_vram(pipe)
        
        return output_path, f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼å·²ä¿å­˜ä¸º {output_path}"
        
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        return None, f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}\n\nè¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š\n{error_trace}"

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="WanVACE è§†é¢‘ç”Ÿæˆå™¨", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ¬ WanVACE è§†é¢‘ç”Ÿæˆå™¨")
        gr.Markdown("ä½¿ç”¨Wan2.1-VACE-14Bæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡è§†é¢‘")
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“¤ è¾“å…¥è®¾ç½®")
                
                with gr.Tabs() as input_tabs:
                    with gr.TabItem("ğŸ¬ VACEæ¨¡å¼ (æ·±åº¦è§†é¢‘+å‚è€ƒå›¾ç‰‡)", id="vace_tab"):
                        depth_video = gr.Video(
                            label="æ·±åº¦è§†é¢‘ (Depth Video)",
                            height=200,
                        )
                        
                        video_info = gr.Textbox(
                            label="è§†é¢‘ä¿¡æ¯",
                            value="æœªä¸Šä¼ è§†é¢‘",
                            interactive=False,
                            info="æ˜¾ç¤ºä¸Šä¼ è§†é¢‘çš„åŸå§‹ä¿¡æ¯"
                        )
                        
                        reference_image = gr.Image(
                            label="å‚è€ƒå›¾ç‰‡ (Reference Image)",
                            height=200,
                            type="pil",
                        )
                        
                        reference_image_info = gr.Textbox(
                            label="å‚è€ƒå›¾ç‰‡ä¿¡æ¯",
                            value="æœªä¸Šä¼ å›¾ç‰‡",
                            interactive=False,
                            info="æ˜¾ç¤ºå‚è€ƒå›¾ç‰‡çš„å°ºå¯¸ã€æ ¼å¼ç­‰ä¿¡æ¯"
                        )
                    
                    with gr.TabItem("ğŸ–¼ï¸ é¦–å°¾å¸§æ¨¡å¼ (é¦–å¸§+å°¾å¸§)", id="inp_tab"):
                        first_frame = gr.Image(
                            label="é¦–å¸§å›¾ç‰‡ (First Frame)",
                            height=200,
                            type="pil",
                        )
                        
                        first_frame_info = gr.Textbox(
                            label="é¦–å¸§å›¾ç‰‡ä¿¡æ¯",
                            value="æœªä¸Šä¼ å›¾ç‰‡",
                            interactive=False,
                            info="æ˜¾ç¤ºé¦–å¸§å›¾ç‰‡çš„å°ºå¯¸ã€æ ¼å¼ç­‰ä¿¡æ¯"
                        )
                        
                        last_frame = gr.Image(
                            label="å°¾å¸§å›¾ç‰‡ (Last Frame)",
                            height=200,
                            type="pil"
                        )
                        
                        last_frame_info = gr.Textbox(
                            label="å°¾å¸§å›¾ç‰‡ä¿¡æ¯",
                            value="æœªä¸Šä¼ å›¾ç‰‡",
                            interactive=False,
                            info="æ˜¾ç¤ºå°¾å¸§å›¾ç‰‡çš„å°ºå¯¸ã€æ ¼å¼ç­‰ä¿¡æ¯"
                        )
                

                
            with gr.Column(scale=1):
                gr.Markdown("## âš™ï¸ å‚æ•°è®¾ç½®")
                
                # æ¨¡å‹é€‰æ‹©
                model_id = gr.Dropdown(
                    label="é€‰æ‹©æ¨¡å‹",
                    choices=VACE_MODELS,
                    value="PAI/Wan2.2-VACE-Fun-A14B",
                    info="æ¨¡å‹ä¼šæ ¹æ®é€‰æ‹©çš„è¾“å…¥æ¨¡å¼è‡ªåŠ¨æ›´æ–°"
                )
                
                prompt = gr.Textbox(
                    label="æ­£é¢æç¤ºè¯",
                    placeholder="ä¸¤åªå¯çˆ±çš„æ©˜çŒ«æˆ´ä¸Šæ‹³å‡»æ‰‹å¥—ï¼Œç«™åœ¨ä¸€ä¸ªæ‹³å‡»å°ä¸Šææ–—ã€‚",
                    lines=3
                )
                
                negative_prompt = gr.Textbox(
                    label="è´Ÿé¢æç¤ºè¯",
                    placeholder="è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…...",
                    lines=4
                )
                
                with gr.Row():
                    seed = gr.Number(
                        label="éšæœºç§å­",
                        value=-1,
                        minimum=-1,
                    )
                    fps = gr.Slider(
                        label="FPS",
                        value=16,
                        minimum=1,
                        maximum=60,
                        step=1
                    )
                
                # å®½é«˜æ¯”é€‰æ‹©
                aspect_ratio = gr.Dropdown(
                    label="å®½é«˜æ¯”",
                    choices=list(ASPECT_RATIOS_14b.keys()),
                    value="16:9_low",
                    info="é€‰æ‹©é¢„è®¾çš„å®½é«˜æ¯”ï¼Œæˆ–æ‰‹åŠ¨è®¾ç½®å°ºå¯¸"
                )
                
                # æ˜¾å­˜ç®¡ç†
                with gr.Row():
                    clear_vram_btn = gr.Button("ğŸ§¹ é‡Šæ”¾æ˜¾å­˜", variant="secondary", size="sm")
                    refresh_vram_btn = gr.Button("ğŸ”„ åˆ·æ–°æ˜¾å­˜ä¿¡æ¯", variant="secondary", size="sm")
                
                vram_info = gr.Textbox(
                    label="æ˜¾å­˜çŠ¶æ€",
                    value="ç‚¹å‡»åˆ·æ–°æŒ‰é’®æŸ¥çœ‹æ˜¾å­˜ä¿¡æ¯",
                    interactive=False,
                    info="æ˜¾ç¤ºå½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ"
                )
                
                with gr.Row():
                    width = gr.Number(
                        label="è§†é¢‘å®½åº¦",
                        value=832,
                        minimum=256,
                        maximum=1280,
                        step=64,
                        info="è§†é¢‘å®½åº¦ï¼ˆåƒç´ ï¼‰"
                    )
                    height = gr.Number(
                        label="è§†é¢‘é«˜åº¦",
                        value=480,
                        minimum=256,
                        maximum=1280,
                        step=64,
                        info="è§†é¢‘é«˜åº¦ï¼ˆåƒç´ ï¼‰"
                    )
                
                quality = gr.Slider(
                    label="è´¨é‡",
                    value=8,
                    minimum=1,
                    maximum=10,
                    step=1,
                    info="1=æœ€ä½è´¨é‡ï¼Œ10=æœ€é«˜è´¨é‡"
                )
                
                # æ–°å¢çš„é«˜çº§å‚æ•°è®¾ç½®
                gr.Markdown("### ğŸ”§ é«˜çº§å‚æ•°è®¾ç½®")
                
                with gr.Row():
                    num_frames = gr.Number(
                        label="è§†é¢‘å¸§æ•°",
                        value=81,
                        minimum=16,
                        maximum=256,
                        step=1,
                        info="è§†é¢‘æ€»å¸§æ•°ï¼Œå»ºè®®16-256ä¹‹é—´"
                    )
                    num_inference_steps = gr.Number(
                        label="æ¨ç†æ­¥æ•°",
                        value=40,
                        minimum=10,
                        maximum=100,
                        step=1,
                        info="æ¨ç†æ­¥æ•°ï¼Œæ­¥æ•°è¶Šå¤šè´¨é‡è¶Šé«˜ä½†é€Ÿåº¦è¶Šæ…¢"
                    )
                
                with gr.Row():
                    vram_limit = gr.Slider(
                        label="æ˜¾å­˜å ç”¨é‡é™åˆ¶",
                        value=6.0,
                        minimum=0.0,
                        maximum=100.0,
                        step=1,
                        info="æ˜¾å­˜å ç”¨é‡é™åˆ¶ï¼ˆGBï¼‰ï¼Œå½±å“æ˜¾å­˜ä½¿ç”¨å’Œæ€§èƒ½"
                    )
                    tiled_checkbox = gr.Checkbox(
                        label="Tiled VAE Decode", 
                        value=True, 
                        info="ç¦ç”¨å¯èƒ½å¯¼è‡´VAEé”™è¯¯ï¼Œä½†å¯æé«˜æ€§èƒ½"
                    )
                
                generate_btn = gr.Button("ğŸ¬ ç”Ÿæˆè§†é¢‘", variant="primary", size="lg")
        
        with gr.Row():
            gr.Markdown("## ğŸ“¹ è¾“å‡ºç»“æœ")
        
        with gr.Row():
            output_video = gr.Video(label="ç”Ÿæˆçš„è§†é¢‘")
            output_status = gr.Textbox(label="ç”ŸæˆçŠ¶æ€", interactive=False)
        
        # Tabåˆ‡æ¢æ—¶æ›´æ–°æ¨¡å‹é€‰æ‹©
        input_tabs.select(
            fn=handle_tab_change,
            outputs=[model_id]
        )
        
        # å®½é«˜æ¯”é€‰æ‹©å˜åŒ–æ—¶è‡ªåŠ¨æ›´æ–°å°ºå¯¸
        aspect_ratio.change(
            fn=update_dimensions,
            inputs=[aspect_ratio],
            outputs=[height, width]
        )
        
        # è§†é¢‘ä¸Šä¼ æ—¶è‡ªåŠ¨æ›´æ–°è§†é¢‘ä¿¡æ¯
        depth_video.change(
            fn=get_video_info,
            inputs=[depth_video],
            outputs=[video_info]
        )
        
        # å›¾ç‰‡ä¸Šä¼ æ—¶è‡ªåŠ¨æ›´æ–°å›¾ç‰‡ä¿¡æ¯
        reference_image.change(
            fn=get_image_info,
            inputs=[reference_image],
            outputs=[reference_image_info]
        )
        
        first_frame.change(
            fn=get_image_info,
            inputs=[first_frame],
            outputs=[first_frame_info]
        )
        
        last_frame.change(
            fn=get_image_info,
            inputs=[last_frame],
            outputs=[last_frame_info]
        )
        
        # æ˜¾å­˜ç®¡ç†æŒ‰é’®äº‹ä»¶
        clear_vram_btn.click(
            fn=clear_vram,
            outputs=[vram_info]
        )
        
        refresh_vram_btn.click(
            fn=get_vram_info,
            outputs=[vram_info]
        )
        
        generate_btn.click(
            fn=process_video,
            inputs=[
                depth_video,
                reference_image,
                prompt,
                negative_prompt,
                seed,
                fps,
                quality,
                height,
                width,
                num_frames,
                num_inference_steps,
                vram_limit,
                model_id,
                first_frame,
                last_frame,
                tiled_checkbox
            ],
            outputs=[output_video, output_status]
        )
        
        gr.Markdown("## ğŸ“š ä½¿ç”¨è¯´æ˜")
        gr.Markdown("""
        1. **é€‰æ‹©è¾“å…¥æ¨¡å¼**ï¼šç‚¹å‡»"VACEæ¨¡å¼"æˆ–"é¦–å°¾å¸§æ¨¡å¼"æ ‡ç­¾é¡µ
        2. **é€‰æ‹©æ¨¡å‹**ï¼šæ¨¡å‹ä¼šæ ¹æ®é€‰æ‹©çš„æ ‡ç­¾é¡µè‡ªåŠ¨æ›´æ–°ï¼Œé€‰æ‹©é€‚åˆçš„æ¨¡å‹ï¼ˆ14Bè´¨é‡æ›´é«˜ï¼Œ1.3Bé€Ÿåº¦æ›´å¿«ï¼‰
        3. **ä¸Šä¼ æ–‡ä»¶**ï¼šæ ¹æ®é€‰æ‹©çš„æ¨¡å¼ä¸Šä¼ ç›¸åº”çš„æ–‡ä»¶
        4. **è®¾ç½®å‚æ•°**ï¼šè°ƒæ•´æç¤ºè¯ã€ç§å­ã€FPSã€è´¨é‡ã€è§†é¢‘å°ºå¯¸å’Œé«˜çº§å‚æ•°
        5. **ç”Ÿæˆè§†é¢‘**ï¼šç‚¹å‡»"ç”Ÿæˆè§†é¢‘"æŒ‰é’®å¼€å§‹å¤„ç†ï¼ˆé¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨åˆå§‹åŒ–æ¨¡å‹ï¼‰
        
        **æ ‡ç­¾é¡µä¸æ¨¡å‹å¯¹åº”å…³ç³»**ï¼š
        - **ğŸ¬ VACEæ¨¡å¼æ ‡ç­¾é¡µ**ï¼šæ˜¾ç¤ºVACEæ¨¡å‹
          - **PAI/Wan2.2-VACE-Fun-A14B**ï¼šé«˜è´¨é‡VACEæ¨¡å‹ï¼Œç”Ÿæˆæ•ˆæœæ›´å¥½ï¼Œä½†éœ€è¦æ›´å¤šæ˜¾å­˜å’Œè®¡ç®—æ—¶é—´
          - **Wan-AI/Wan2.1-VACE-1.3B**ï¼šè½»é‡çº§VACEæ¨¡å‹ï¼Œç”Ÿæˆé€Ÿåº¦æ›´å¿«ï¼Œæ˜¾å­˜éœ€æ±‚æ›´å°‘ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•
        - **ğŸ–¼ï¸ é¦–å°¾å¸§æ¨¡å¼æ ‡ç­¾é¡µ**ï¼šæ˜¾ç¤ºInPæ¨¡å‹
          - **PAI/Wan2.2-Fun-A14B-InP**ï¼šé«˜è´¨é‡é¦–å°¾å¸§æ¨¡å‹ï¼Œ14Bå‚æ•°
          - **PAI/Wan2.1-Fun-V1.1-1.3B-InP**ï¼šè½»é‡çº§é¦–å°¾å¸§æ¨¡å‹ï¼Œ1.3Bå‚æ•°
        
        **è¾“å…¥æ¨¡å¼è¯¦ç»†è¯´æ˜**ï¼š
        - **VACEæ¨¡å¼**ï¼šä¸Šä¼ æ·±åº¦è§†é¢‘å’Œ/æˆ–å‚è€ƒå›¾ç‰‡
          - å¯ä»¥å•ç‹¬ä½¿ç”¨æ·±åº¦è§†é¢‘æˆ–å‚è€ƒå›¾ç‰‡
          - ä¹Ÿå¯ä»¥åŒæ—¶ä½¿ç”¨ä¸¤è€…è·å¾—æ›´å¥½çš„æ•ˆæœ
          - æ·±åº¦è§†é¢‘æä¾›è¿åŠ¨ä¿¡æ¯ï¼Œå‚è€ƒå›¾ç‰‡æä¾›è§†è§‰é£æ ¼
        - **é¦–å°¾å¸§æ¨¡å¼**ï¼šä¸Šä¼ é¦–å¸§å›¾ç‰‡ï¼ˆå¿…éœ€ï¼‰å’Œå°¾å¸§å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
          - é¦–å¸§å›¾ç‰‡æ˜¯å¿…éœ€çš„ï¼Œç”¨äºå®šä¹‰è§†é¢‘çš„èµ·å§‹çŠ¶æ€
          - å°¾å¸§å›¾ç‰‡æ˜¯å¯é€‰çš„ï¼Œå¦‚æœæä¾›ä¼šç”Ÿæˆä»é¦–å¸§åˆ°å°¾å¸§çš„è¿‡æ¸¡è§†é¢‘
          - å¦‚æœä¸æä¾›å°¾å¸§ï¼Œåˆ™åªä½¿ç”¨é¦–å¸§ç”Ÿæˆè§†é¢‘
        
        **æ™ºèƒ½æ¨¡å‹åˆ‡æ¢**ï¼š
        - åˆ‡æ¢æ ‡ç­¾é¡µæ—¶ï¼Œæ¨¡å‹é€‰æ‹©ä¼šè‡ªåŠ¨æ›´æ–°ä¸ºå¯¹åº”æ¨¡å¼çš„æ¨¡å‹
        - VACEæ¨¡å¼æ ‡ç­¾é¡µåªæ˜¾ç¤ºVACEæ¨¡å‹ï¼ˆWan-AI/Wan2.1-VACE-*ï¼‰
        - é¦–å°¾å¸§æ¨¡å¼æ ‡ç­¾é¡µåªæ˜¾ç¤ºInPæ¨¡å‹ï¼ˆPAI/Wan2.1-Fun-V1.1-*-InPï¼‰
        - ç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æ¯ä¸ªæ¨¡å¼çš„é»˜è®¤æ¨¡å‹ï¼ˆ14Bç‰ˆæœ¬ï¼‰
        
        **è§†é¢‘å°ºå¯¸**ï¼š
        - é€‰æ‹©é¢„è®¾å®½é«˜æ¯”æˆ–æ‰‹åŠ¨è®¾ç½®å°ºå¯¸
        - æ”¯æŒå¤šç§å¸¸ç”¨å®½é«˜æ¯”ï¼š1:1ã€4:3ã€16:9ã€9:16ç­‰
        - é«˜åº¦å’Œå®½åº¦èŒƒå›´ï¼š256-1280åƒç´ 
        - å»ºè®®ä½¿ç”¨64çš„å€æ•°ä»¥è·å¾—æœ€ä½³æ€§èƒ½
        - é»˜è®¤å°ºå¯¸ï¼š832x480ï¼ˆ16:9_lowï¼Œé€‚åˆå¤§å¤šæ•°æ˜¾ç¤ºå™¨ï¼‰
        
        **æ³¨æ„äº‹é¡¹**ï¼š
        - VACEæ¨¡å¼ï¼šè‡³å°‘éœ€è¦ä¸Šä¼ æ·±åº¦è§†é¢‘æˆ–å‚è€ƒå›¾ç‰‡ä¸­çš„ä¸€ç§
        - é¦–å°¾å¸§æ¨¡å¼ï¼šå¿…é¡»ä¸Šä¼ é¦–å¸§å›¾ç‰‡ï¼Œå°¾å¸§å›¾ç‰‡å¯é€‰
        - é¦–æ¬¡ç”Ÿæˆæ—¶ä¼šè‡ªåŠ¨åˆå§‹åŒ–æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…
        - è§†é¢‘ç”Ÿæˆéœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
        - å»ºè®®ä½¿ç”¨è¾ƒå°çš„è§†é¢‘æ–‡ä»¶ä»¥æé«˜å¤„ç†é€Ÿåº¦
        - è¾ƒå¤§çš„è§†é¢‘å°ºå¯¸ä¼šå¢åŠ å¤„ç†æ—¶é—´å’Œæ˜¾å­˜éœ€æ±‚
        - æ·±åº¦è§†é¢‘å°ºå¯¸åº”ä¸ç›®æ ‡å°ºå¯¸å…¼å®¹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒæ•´
        - å¦‚æœå‡ºç°å°ºå¯¸é”™è¯¯ï¼Œè¯·å°è¯•ä½¿ç”¨ä¸åŸå§‹è§†é¢‘ç›¸è¿‘çš„å®½é«˜æ¯”
        - å¦‚æœå‡ºç°VAEè§£ç é”™è¯¯ï¼Œè¯·å°è¯•ç¦ç”¨"Tiled VAE Decode"é€‰é¡¹
        
        **é«˜çº§å‚æ•°è¯´æ˜**ï¼š
        - **è§†é¢‘å¸§æ•°**ï¼šæ§åˆ¶ç”Ÿæˆè§†é¢‘çš„é•¿åº¦ï¼Œå¸§æ•°è¶Šå¤šè§†é¢‘è¶Šé•¿
        - **æ¨ç†æ­¥æ•°**ï¼šæ§åˆ¶ç”Ÿæˆè´¨é‡ï¼Œæ­¥æ•°è¶Šå¤šè´¨é‡è¶Šé«˜ä½†é€Ÿåº¦è¶Šæ…¢
        - **æ˜¾å­˜å ç”¨é‡é™åˆ¶**ï¼šæ§åˆ¶æ˜¾å­˜ä½¿ç”¨ï¼Œæ•°å€¼è¶Šå¤§æ˜¾å­˜å ç”¨è¶Šå¤šä½†æ€§èƒ½è¶Šå¥½ï¼ˆ0-100GBï¼‰
        - **Tiled VAE Decode**ï¼šå¯ç”¨åˆ†å—VAEè§£ç ï¼Œå¯æé«˜æ€§èƒ½ä½†å¯èƒ½å¯¼è‡´VAEé”™è¯¯
        
        **æ˜¾å­˜ç®¡ç†**ï¼š
        - è°ƒè¯•ä¸­æ–­åç‚¹å‡»"é‡Šæ”¾æ˜¾å­˜"æŒ‰é’®æ¸…ç†æ˜¾å­˜
        - ä½¿ç”¨"åˆ·æ–°æ˜¾å­˜ä¿¡æ¯"æŸ¥çœ‹å½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
        - æ˜¾å­˜ä¸è¶³æ—¶å»ºè®®å…ˆé‡Šæ”¾æ˜¾å­˜å†é‡æ–°ç”Ÿæˆ
        - å¯ä»¥é€šè¿‡è°ƒæ•´æ˜¾å­˜å ç”¨é‡é™åˆ¶æ¥å¹³è¡¡æ˜¾å­˜ä½¿ç”¨å’Œæ€§èƒ½ï¼ˆ0-100GBæ»‘å—æ§åˆ¶ï¼‰
        - åˆ‡æ¢æ¨¡å‹æ—¶ä¼šè‡ªåŠ¨æ¸…ç†æ˜¾å­˜å¹¶é‡æ–°åˆå§‹åŒ–
        
        **ä½¿ç”¨æç¤º**ï¼š
        - æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ ‡ç­¾é¡µ
        - VACEæ¨¡å¼æ ‡ç­¾é¡µé€‚åˆæœ‰æ·±åº¦è§†é¢‘æˆ–å‚è€ƒå›¾ç‰‡çš„åœºæ™¯
        - é¦–å°¾å¸§æ¨¡å¼æ ‡ç­¾é¡µé€‚åˆæœ‰èµ·å§‹å’Œç»“æŸå›¾ç‰‡çš„åœºæ™¯
        - ç³»ç»Ÿä¼šæ ¹æ®æ ‡ç­¾é¡µè‡ªåŠ¨æ˜¾ç¤ºç›¸åº”çš„è¾“å…¥ç•Œé¢å’Œæ¨¡å‹é€‰é¡¹
        - åˆ‡æ¢æ ‡ç­¾é¡µæ—¶ä¼šè‡ªåŠ¨æ›´æ–°æ¨¡å‹é€‰æ‹©ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒæ•´
        """)
    
    return demo

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7861,
        show_error=True
    )
